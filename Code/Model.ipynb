{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "122e6a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timeline rows: 370\n",
      "              timestamp     rms_db  rms_delta     centroid   rolloff  \\\n",
      "0   1767433733686834000        NaN        NaN          NaN       NaN   \n",
      "1   1767433734361189000        NaN        NaN          NaN       NaN   \n",
      "2   1767433735001224000        NaN        NaN          NaN       NaN   \n",
      "3   1767433735747108000        NaN        NaN          NaN       NaN   \n",
      "4   1767433737897063000        NaN        NaN          NaN       NaN   \n",
      "5   1767433738590481000        NaN        NaN          NaN       NaN   \n",
      "6   1767433739227894000        NaN        NaN          NaN       NaN   \n",
      "7   1767433739939375000        NaN        NaN          NaN       NaN   \n",
      "8   1767433739939670000        NaN        NaN          NaN       NaN   \n",
      "9   1767433740624612000        NaN        NaN          NaN       NaN   \n",
      "10  1767433741276642000        NaN        NaN          NaN       NaN   \n",
      "11  1767433741899313000        NaN        NaN          NaN       NaN   \n",
      "12  1767433748716759000 -39.901203   0.009741  3108.939008  7640.625   \n",
      "13  1767433748738158000 -36.432194   0.004965  2408.774710  5062.500   \n",
      "14  1767433748759361000 -37.604492  -0.001904  2559.909662  5671.875   \n",
      "15  1767433748780686000 -37.315090   0.000446  3533.607430  8953.125   \n",
      "16  1767433748801852000 -37.144226   0.000271  2059.612835  3656.250   \n",
      "17  1767433748823261000 -38.198895  -0.001589  2898.768668  6890.625   \n",
      "18  1767433748844337000 -38.065762   0.000190  3349.363031  8390.625   \n",
      "19  1767433748866023000 -38.304207  -0.000338  1352.168168  1125.000   \n",
      "\n",
      "    flatness       low       mid      high  spectral_flux  onset_strength  \\\n",
      "0        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "1        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "2        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "3        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "4        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "5        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "6        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "7        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "8        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "9        NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "10       NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "11       NaN       NaN       NaN       NaN            NaN             NaN   \n",
      "12  0.345908  2.638920  0.145022  0.017355       0.314522        0.009741   \n",
      "13  0.267725  4.031806  0.130307  0.015865       0.183380        0.004965   \n",
      "14  0.283774  3.688309  0.112780  0.015066       0.111395        0.000000   \n",
      "15  0.394544  3.467521  0.241417  0.029735       0.145176        0.000446   \n",
      "16  0.226634  3.658341  0.095587  0.010908       0.145291        0.000271   \n",
      "17  0.322437  3.396877  0.139540  0.017667       0.102079        0.000000   \n",
      "18  0.374078  3.134024  0.211810  0.024762       0.110046        0.000190   \n",
      "19  0.141814  3.190016  0.065408  0.005263       0.136811        0.000000   \n",
      "\n",
      "    device_id  channel  note velocity  cc_number  cc_value  program_number  \\\n",
      "0          11        0  11.0     None        NaN       2.0             NaN   \n",
      "1          11        0  32.0     None        NaN       2.0             NaN   \n",
      "2          11        1   NaN     None       11.0       0.0             NaN   \n",
      "3          11        1   NaN     None       11.0       2.0             NaN   \n",
      "4          11        1   NaN     None       11.0       3.0             NaN   \n",
      "5          11        1   NaN     None       11.0       1.0             NaN   \n",
      "6          11        1   NaN     None       32.0       2.0             NaN   \n",
      "7          11        1   NaN     None        2.0      32.0             NaN   \n",
      "8          11        1   NaN     None        2.0       3.0             NaN   \n",
      "9          11        1   NaN     None        2.0       0.0             NaN   \n",
      "10         11        1   NaN     None       32.0       2.0             NaN   \n",
      "11         11        1   NaN     None       11.0       3.0             NaN   \n",
      "12         11        1   NaN     None       11.0       3.0             NaN   \n",
      "13         11        1   NaN     None       11.0       3.0             NaN   \n",
      "14         11        1   NaN     None       11.0       3.0             NaN   \n",
      "15         11        1   NaN     None       11.0       3.0             NaN   \n",
      "16         11        1   NaN     None       11.0       3.0             NaN   \n",
      "17         11        1   NaN     None       11.0       3.0             NaN   \n",
      "18         11        1   NaN     None       11.0       3.0             NaN   \n",
      "19         11        1   NaN     None       11.0       3.0             NaN   \n",
      "\n",
      "              type  \n",
      "0        polytouch  \n",
      "1        polytouch  \n",
      "2   control_change  \n",
      "3   control_change  \n",
      "4   control_change  \n",
      "5   control_change  \n",
      "6   control_change  \n",
      "7   control_change  \n",
      "8   control_change  \n",
      "9   control_change  \n",
      "10  control_change  \n",
      "11  control_change  \n",
      "12  control_change  \n",
      "13  control_change  \n",
      "14  control_change  \n",
      "15  control_change  \n",
      "16  control_change  \n",
      "17  control_change  \n",
      "18  control_change  \n",
      "19  control_change  \n"
     ]
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "DB_PATH = \"data/clean_music_data.db\"\n",
    "\n",
    "# -----------------------------\n",
    "# Load tables\n",
    "# -----------------------------\n",
    "with sqlite3.connect(DB_PATH) as conn:\n",
    "    audio_df = pd.read_sql_query(\"SELECT * FROM audio_features ORDER BY timestamp\", conn)\n",
    "    midi_df = pd.read_sql_query(\"SELECT * FROM midi_events ORDER BY timestamp\", conn)\n",
    "\n",
    "audio_columns = ['rms_db','rms_delta','centroid','rolloff','flatness','low','mid','high','spectral_flux','onset_strength']\n",
    "midi_columns = ['device_id','channel','note','velocity','cc_number','cc_value','program_number','type']\n",
    "\n",
    "# -----------------------------\n",
    "# Sort tables just in case\n",
    "# -----------------------------\n",
    "audio_df = audio_df.sort_values('timestamp').reset_index(drop=True)\n",
    "midi_df = midi_df.sort_values('timestamp').reset_index(drop=True)\n",
    "\n",
    "# -----------------------------\n",
    "# Pointers\n",
    "# -----------------------------\n",
    "audio_idx = 0\n",
    "midi_idx = 0\n",
    "n_audio = len(audio_df)\n",
    "n_midi = len(midi_df)\n",
    "\n",
    "# -----------------------------\n",
    "# Output timeline\n",
    "# -----------------------------\n",
    "timeline_rows = []\n",
    "\n",
    "# Keep track of last known states\n",
    "last_audio = {col: None for col in audio_columns}\n",
    "last_midi = {col: None for col in midi_columns}\n",
    "\n",
    "# -----------------------------\n",
    "# All timestamps sorted\n",
    "# -----------------------------\n",
    "all_timestamps = sorted(\n",
    "    list(audio_df['timestamp']) + list(midi_df['timestamp'])\n",
    ")\n",
    "\n",
    "for ts in all_timestamps:\n",
    "    # Update audio if this timestamp matches\n",
    "    if audio_idx < n_audio and audio_df.at[audio_idx, 'timestamp'] == ts:\n",
    "        for col in audio_columns:\n",
    "            last_audio[col] = audio_df.at[audio_idx, col]\n",
    "        audio_idx += 1\n",
    "\n",
    "    # Update midi if this timestamp matches\n",
    "    if midi_idx < n_midi and midi_df.at[midi_idx, 'timestamp'] == ts:\n",
    "        for col in midi_columns:\n",
    "            last_midi[col] = midi_df.at[midi_idx, col]\n",
    "        midi_idx += 1\n",
    "\n",
    "    # Build row with current states\n",
    "    row = {'timestamp': ts}\n",
    "    row.update(last_audio)\n",
    "    row.update(last_midi)\n",
    "    timeline_rows.append(row)\n",
    "\n",
    "# -----------------------------\n",
    "# Create DataFrame\n",
    "# -----------------------------\n",
    "timeline_df = pd.DataFrame(timeline_rows)\n",
    "\n",
    "# -----------------------------\n",
    "# Check results\n",
    "# -----------------------------\n",
    "print(\"Timeline rows:\", len(timeline_df))\n",
    "print(timeline_df.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1e02fcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline_df.to_csv(\"merged_audio_midi.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "995a2a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5b530b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<positron-console-cell-4>:16: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-output RF accuracy: 0.8243243243243243\n",
      "Predicted next MIDI (channel, cc_number, cc_value): [ 6. 12.  0.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# -----------------------------\n",
    "# Columns\n",
    "# -----------------------------\n",
    "audio_columns = ['rms_db','rms_delta','centroid','rolloff','flatness','low','mid','high','spectral_flux','onset_strength']\n",
    "midi_columns = ['device_id','channel','note','velocity','cc_number','cc_value','program_number','type']\n",
    "\n",
    "# -----------------------------\n",
    "# Fill missing numeric values\n",
    "# -----------------------------\n",
    "timeline_df[audio_columns + midi_columns[:-1]] = timeline_df[audio_columns + midi_columns[:-1]].fillna(0)\n",
    "\n",
    "# -----------------------------\n",
    "# Encode string 'type'\n",
    "# -----------------------------\n",
    "type_encoder = LabelEncoder()\n",
    "timeline_df['type_enc'] = type_encoder.fit_transform(timeline_df['type'].fillna('none'))\n",
    "\n",
    "# -----------------------------\n",
    "# Features and targets\n",
    "# -----------------------------\n",
    "feature_columns = audio_columns + midi_columns[:-1] + ['type_enc']\n",
    "\n",
    "# Predict next MIDI events\n",
    "timeline_df['next_channel'] = timeline_df['channel'].shift(-1)\n",
    "timeline_df['next_cc_number'] = timeline_df['cc_number'].shift(-1)\n",
    "timeline_df['next_cc_value'] = timeline_df['cc_value'].shift(-1)\n",
    "\n",
    "# Drop last row (no next)\n",
    "timeline_df = timeline_df.dropna(subset=['next_channel','next_cc_number','next_cc_value'])\n",
    "\n",
    "X = timeline_df[feature_columns]\n",
    "y = timeline_df[['next_channel','next_cc_number','next_cc_value']]\n",
    "\n",
    "# -----------------------------\n",
    "# Train/test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -----------------------------\n",
    "# Multi-output Random Forest\n",
    "# -----------------------------\n",
    "multi_rf = MultiOutputClassifier(\n",
    "    RandomForestClassifier(n_estimators=100, random_state=42)\n",
    ")\n",
    "multi_rf.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate\n",
    "# -----------------------------\n",
    "score = multi_rf.score(X_test, y_test)\n",
    "print(\"Multi-output RF accuracy:\", score)\n",
    "\n",
    "# -----------------------------\n",
    "# Example prediction\n",
    "# -----------------------------\n",
    "example_row = X_test.iloc[0:1]\n",
    "pred = multi_rf.predict(example_row)\n",
    "print(\"Predicted next MIDI (channel, cc_number, cc_value):\", pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "947a0a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost multi-output accuracy: 0.7972972972972973\n",
      "Predicted next MIDI (channel, cc_number, cc_value): [ 1. 32.  0.]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# -----------------------------\n",
    "# Columns\n",
    "# -----------------------------\n",
    "audio_columns = [\n",
    "    'rms_db','rms_delta','centroid','rolloff','flatness',\n",
    "    'low','mid','high','spectral_flux','onset_strength'\n",
    "]\n",
    "\n",
    "midi_columns = [\n",
    "    'device_id','channel','note','velocity',\n",
    "    'cc_number','cc_value','program_number','type'\n",
    "]\n",
    "\n",
    "# -----------------------------\n",
    "# Fill missing numeric values\n",
    "# -----------------------------\n",
    "timeline_df[audio_columns + midi_columns[:-1]] = (\n",
    "    timeline_df[audio_columns + midi_columns[:-1]].fillna(0)\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Encode MIDI type\n",
    "# -----------------------------\n",
    "type_encoder = LabelEncoder()\n",
    "timeline_df['type_enc'] = type_encoder.fit_transform(\n",
    "    timeline_df['type'].fillna('none')\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Feature set\n",
    "# -----------------------------\n",
    "feature_columns = audio_columns + midi_columns[:-1] + ['type_enc']\n",
    "\n",
    "# -----------------------------\n",
    "# Targets (next event)\n",
    "# -----------------------------\n",
    "timeline_df['next_channel']   = timeline_df['channel'].shift(-1)\n",
    "timeline_df['next_cc_number'] = timeline_df['cc_number'].shift(-1)\n",
    "timeline_df['next_cc_value']  = timeline_df['cc_value'].shift(-1)\n",
    "\n",
    "timeline_df = timeline_df.dropna(\n",
    "    subset=['next_channel','next_cc_number','next_cc_value']\n",
    ")\n",
    "\n",
    "X = timeline_df[feature_columns]\n",
    "y = timeline_df[['next_channel','next_cc_number','next_cc_value']]\n",
    "\n",
    "# -----------------------------\n",
    "# Train/test split\n",
    "# -----------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Gradient Boosted Trees\n",
    "# -----------------------------\n",
    "gb_model = MultiOutputClassifier(\n",
    "    HistGradientBoostingClassifier(\n",
    "        max_depth=6,\n",
    "        learning_rate=0.05,\n",
    "        max_iter=300,\n",
    "        random_state=42\n",
    "    )\n",
    ")\n",
    "\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# -----------------------------\n",
    "# Evaluate\n",
    "# -----------------------------\n",
    "score = gb_model.score(X_test, y_test)\n",
    "print(\"Gradient Boost multi-output accuracy:\", score)\n",
    "\n",
    "# -----------------------------\n",
    "# Example prediction\n",
    "# -----------------------------\n",
    "example_row = X_test.iloc[[0]]\n",
    "pred = gb_model.predict(example_row)\n",
    "\n",
    "print(\"Predicted next MIDI (channel, cc_number, cc_value):\", pred[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffcc8c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LSTM Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f868d346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e7e8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_columns = [\n",
    "    'rms_db','rms_delta','centroid','rolloff','flatness',\n",
    "    'low','mid','high','spectral_flux','onset_strength'\n",
    "]\n",
    "\n",
    "midi_columns = ['channel','cc_number','cc_value','type']\n",
    "\n",
    "df = timeline_df.copy()\n",
    "\n",
    "df[audio_columns + ['channel','cc_number','cc_value']] = (\n",
    "    df[audio_columns + ['channel','cc_number','cc_value']]\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "type_encoder = LabelEncoder()\n",
    "df['type_enc'] = type_encoder.fit_transform(df['type'].fillna('none'))\n",
    "\n",
    "feature_columns = audio_columns + ['channel','cc_number','cc_value','type_enc']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df[feature_columns] = scaler.fit_transform(df[feature_columns])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1321d236",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN = 16   # try 8, 16, 32 later\n",
    "\n",
    "X_seq = []\n",
    "y_channel = []\n",
    "y_cc = []\n",
    "y_value = []\n",
    "\n",
    "for i in range(len(df) - SEQ_LEN - 1):\n",
    "    window = df.iloc[i:i+SEQ_LEN]\n",
    "\n",
    "    X_seq.append(window[feature_columns].values)\n",
    "\n",
    "    y_channel.append(df.iloc[i+SEQ_LEN]['channel'])\n",
    "    y_cc.append(df.iloc[i+SEQ_LEN]['cc_number'])\n",
    "    y_value.append(df.iloc[i+SEQ_LEN]['cc_value'])\n",
    "\n",
    "X_seq = np.array(X_seq, dtype=np.float32)\n",
    "y_channel = np.array(y_channel, dtype=np.int64)\n",
    "y_cc = np.array(y_cc, dtype=np.int64)\n",
    "y_value = np.array(y_value, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d785e618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class MidiLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_dim,\n",
    "            hidden_dim,\n",
    "            num_layers=2,\n",
    "            batch_first=True\n",
    "        )\n",
    "\n",
    "        self.channel_head = nn.Linear(hidden_dim, 16)   # MIDI channels\n",
    "        self.cc_head = nn.Linear(hidden_dim, 128)       # CC numbers\n",
    "        self.value_head = nn.Linear(hidden_dim, 1)      # CC value (regression)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        h = out[:, -1, :]  # last timestep\n",
    "\n",
    "        return (\n",
    "            self.channel_head(h),\n",
    "            self.cc_head(h),\n",
    "            self.value_head(h).squeeze(-1)\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed2d6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = MidiLSTM(input_dim=X_seq.shape[2]).to(device)\n",
    "\n",
    "loss_channel = nn.CrossEntropyLoss()\n",
    "loss_cc = nn.CrossEntropyLoss()\n",
    "loss_value = nn.MSELoss()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7149d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "EPOCHS = 20\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(\n",
    "    torch.tensor(X_seq),\n",
    "    torch.tensor(y_channel),\n",
    "    torch.tensor(y_cc),\n",
    "    torch.tensor(y_value)\n",
    ")\n",
    "\n",
    "loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28ba687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: loss=26.2319\n",
      "Epoch 2: loss=27.3046\n",
      "Epoch 3: loss=22.7234\n",
      "Epoch 4: loss=20.2273\n",
      "Epoch 5: loss=19.4411\n",
      "Epoch 6: loss=20.6384\n",
      "Epoch 7: loss=20.6130\n",
      "Epoch 8: loss=19.6933\n",
      "Epoch 9: loss=19.1931\n",
      "Epoch 10: loss=19.5770\n",
      "Epoch 11: loss=20.3594\n",
      "Epoch 12: loss=19.3813\n",
      "Epoch 13: loss=19.2115\n",
      "Epoch 14: loss=19.2475\n",
      "Epoch 15: loss=18.2824\n",
      "Epoch 16: loss=19.3024\n",
      "Epoch 17: loss=19.4857\n",
      "Epoch 18: loss=22.8322\n",
      "Epoch 19: loss=20.4172\n",
      "Epoch 20: loss=18.7053\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for Xb, ch, cc, val in loader:\n",
    "        Xb = Xb.to(device)\n",
    "        ch = ch.to(device)\n",
    "        cc = cc.to(device)\n",
    "        val = val.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_ch, pred_cc, pred_val = model(Xb)\n",
    "\n",
    "        loss = (\n",
    "            loss_channel(pred_ch, ch) +\n",
    "            loss_cc(pred_cc, cc) +\n",
    "            0.1 * loss_value(pred_val, val)\n",
    "        )\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: loss={total_loss/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8b80210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted channel: 6\n",
      "Predicted CC: 12\n",
      "Predicted CC value: 3\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    example = torch.tensor(X_seq[-1:]).to(device)\n",
    "    ch_pred, cc_pred, val_pred = model(example)\n",
    "\n",
    "    print(\"Predicted channel:\", ch_pred.argmax(dim=1).item())\n",
    "    print(\"Predicted CC:\", cc_pred.argmax(dim=1).item())\n",
    "    print(\"Predicted CC value:\", int(val_pred.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e3d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
